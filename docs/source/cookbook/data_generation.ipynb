{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation Through Workflow in Synthora\n",
    "\n",
    "Workflow is a powerful system in Synthora that can be used to orchestrate \n",
    "agents on solving various problems, allowing users to define their own workflow\n",
    "with a high level of flexibility.\n",
    "\n",
    "In this tutorial, we will show you how to use workflow to generate data. We\n",
    "will start from the simplest SFT data generation and gradually increase the\n",
    "complexity to COT and ToT data generation. Thanks to the flexibility of\n",
    "workflow, the overall process is simple and can be easily customized.\n",
    "\n",
    "Now, if you are ready, let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Before jumping into the fun stuff, there are a few things youâ€™ll need to set up. (Hang tightâ€”itâ€™s worth it!)\n",
    "\n",
    "### Install Synthora\n",
    "Synthora runs on Python 3.8 or later. You can install it quickly using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: synthora in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: asyncio<4.0.0,>=3.4.3 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from synthora) (3.4.3)\n",
      "Requirement already satisfied: docstring-parser<0.17,>=0.16 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from synthora) (0.16)\n",
      "Requirement already satisfied: fastapi<0.116.0,>=0.115.5 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from synthora) (0.115.6)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.55.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from synthora) (1.59.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.1 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from synthora) (2.10.4)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from synthora) (1.0.1)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.9.4 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from synthora) (13.9.4)\n",
      "Requirement already satisfied: websockets<15.0,>=14.1 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from synthora) (14.1)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from fastapi<0.116.0,>=0.115.5->synthora) (0.41.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from fastapi<0.116.0,>=0.115.5->synthora) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from openai<2.0.0,>=1.55.0->synthora) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from openai<2.0.0,>=1.55.0->synthora) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from openai<2.0.0,>=1.55.0->synthora) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from openai<2.0.0,>=1.55.0->synthora) (0.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from openai<2.0.0,>=1.55.0->synthora) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from openai<2.0.0,>=1.55.0->synthora) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from pydantic<3.0.0,>=2.10.1->synthora) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from pydantic<3.0.0,>=2.10.1->synthora) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from rich<14.0.0,>=13.9.4->synthora) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from rich<14.0.0,>=13.9.4->synthora) (2.19.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.0->synthora) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.0->synthora) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.0->synthora) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.0->synthora) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.9.4->synthora) (0.1.2)\n",
      "Requirement already satisfied: colorama in d:\\cache\\pypoetry\\cache\\virtualenvs\\synthora-k2dcfpnb-py3.12\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.55.0->synthora) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~uff (d:\\Cache\\pypoetry\\Cache\\virtualenvs\\synthora-k2DCFpnb-py3.12\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~uff (d:\\Cache\\pypoetry\\Cache\\virtualenvs\\synthora-k2DCFpnb-py3.12\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~uff (d:\\Cache\\pypoetry\\Cache\\virtualenvs\\synthora-k2DCFpnb-py3.12\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install synthora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages & Set Your API Key\n",
    "\n",
    "In this tutorial, weâ€™ll be using OpenAIâ€™s API for data generation. Before we proceed, letâ€™s import the necessary packages and configure the API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from getpass import getpass\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from synthora.agents import VanillaAgent\n",
    "from synthora.agents.tot_agent import ToTAgent\n",
    "from synthora.messages import user\n",
    "from synthora.messages.base import BaseMessage\n",
    "from synthora.prompts.buildin import ZeroShotCoTPrompt\n",
    "from synthora.utils.pydantic_model import get_pydantic_model\n",
    "from synthora.workflows import task\n",
    "from synthora.workflows.base_task import BaseTask\n",
    "from synthora.workflows.scheduler.process_pool import ProcessPoolScheduler\n",
    "from synthora.workflows.scheduler.thread_pool import ThreadPoolScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key here: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Preparation\n",
    "\n",
    "To make comparisons easier, letâ€™s prepare prompts for generating data. A good prompt is the foundation for successful data generation. Take time to think through the kind of data you need and craft your prompt accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\n",
    "    \"How many letters 'r' in the word 'strawberry'?\",\n",
    "    \"9.11 and 9.9, which one is bigger?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple SFT Data Generation\n",
    "\n",
    "Now we can start to get our hands dirty (Finally!). First, we define a task to\n",
    "generate data using a vanilla agent, which is basically the simplest and most\n",
    "basic, classical form of agents.\n",
    "\n",
    "We first define two tasks, one of which is to generate data using a vanilla\n",
    "agent (basically just run a query), and the other is to convert the data to\n",
    "the format we want.\n",
    "\n",
    "> What are tasks in Synthora?\n",
    ">\n",
    "> Tasks are basic units of workload in workflow. They are the smallest units\n",
    "> of work that can be executed independently. In Synthora, tasks are defined\n",
    "> using the `@task` decorator. For more details, please refer to our official\n",
    "> documentation of workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def generate_simple_data(prompt: str) -> List[BaseMessage]:\n",
    "    agent = VanillaAgent.default()\n",
    "    _ = agent.run(prompt)\n",
    "    return agent.history\n",
    "\n",
    "\n",
    "@task\n",
    "def format_data(*resps: List[BaseMessage]) -> List[Dict[str, str]]:\n",
    "    return [\n",
    "        {\n",
    "            \"prompt\": str(resp[0].content),\n",
    "            \"instruct\": str(resp[1].content),\n",
    "            \"response\": str(resp[2].content),\n",
    "        }\n",
    "        for resp in resps\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a workflow to first generate data on each question and\n",
    "format the responses into a readable format like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': '\\nYou are an AI assistant.\\n',\n",
       "  'instruct': \"How many letters 'r' in the word 'strawberry'?\",\n",
       "  'response': 'The word \"strawberry\" has two letters \\'r\\'.'},\n",
       " {'prompt': '\\nYou are an AI assistant.\\n',\n",
       "  'instruct': '9.11 and 9.9, which one is bigger?',\n",
       "  'response': 'The number 9.11 is bigger than 9.9. When comparing the two decimals after the decimal point, 11 is greater than 9.'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow = ThreadPoolScheduler.map(generate_simple_data, problems) >> format_data\n",
    "flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we get some simple data that can be used for simple SFT, which is\n",
    "basically just some query and answers without any intermediate steps. The\n",
    "quality of the data, however, could be low and containing mistakes.\n",
    "\n",
    "Now, what if we want to generate more complex data with better quality? It's\n",
    "time for Chain of Thoughts (COT) or Tree of Thoughts (ToT) data to kick in.\n",
    "\n",
    "## CoT Data Generation\n",
    "\n",
    "Well, it's not that hard to generate CoT data actually. The only thing we need\n",
    "to do is to change the prompt to `ZeroShotCoTPrompt`, which is the simplest\n",
    "prompt guiding the agent to output the thinking steps.\n",
    "\n",
    "> We are using `ZeroShotCoTPrompt`, which is a basical CoT prompts with no \n",
    "> examples, for a quick glance here. If you want to generate data with higher \n",
    "> quality (or more at your preference), you can augment it with some examples \n",
    "> of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': '\\nSolve the following problem step by step. For each step,\\ncarefully explain your reasoning, include all calculations, and state any assumptions you make.\\nEnsure that each step logically leads to the next, and provide a clear and concise final answer at the end.\\nIf relevant, break the problem into smaller parts and address each part individually before combining the results.\\n',\n",
       "  'instruct': \"How many letters 'r' in the word 'strawberry'?\",\n",
       "  'response': 'To solve the problem of finding how many times the letter \\'r\\' appears in the word \\'strawberry\\', we can follow these steps:\\n\\n1. **Identify the word:** We are working with the word \"strawberry\".\\n\\n2. **Look at each letter individually:** \\n   - The first letter is \\'s\\'.\\n   - The second letter is \\'t\\'.\\n   - The third letter is \\'r\\'.\\n   - The fourth letter is \\'a\\'.\\n   - The fifth letter is \\'w\\'.\\n   - The sixth letter is \\'b\\'.\\n   - The seventh letter is \\'e\\'.\\n   - The eighth letter is \\'r\\'.\\n   - The ninth letter is \\'r\\'.\\n   - The tenth letter is \\'y\\'.\\n\\n3. **Count the occurrences of \\'r\\':**\\n   - We see an \\'r\\' at the third position.\\n   - We see an \\'r\\' again at the eighth position.\\n   - We see another \\'r\\' at the ninth position.\\n\\n4. **Add them up:** Considering the positions where we found \\'r\\', we have counted a total of 3 occurrences of the letter \\'r\\'.\\n\\nTherefore, the letter \\'r\\' appears 3 times in the word \"strawberry\".'},\n",
       " {'prompt': '\\nSolve the following problem step by step. For each step,\\ncarefully explain your reasoning, include all calculations, and state any assumptions you make.\\nEnsure that each step logically leads to the next, and provide a clear and concise final answer at the end.\\nIf relevant, break the problem into smaller parts and address each part individually before combining the results.\\n',\n",
       "  'instruct': '9.11 and 9.9, which one is bigger?',\n",
       "  'response': 'To determine which number is bigger between 9.11 and 9.9, we need to compare their decimal representations.\\n\\nStep 1: Analyze the integer part\\n- Both numbers have the integer part of 9, so we need to compare their decimal parts.\\n\\nStep 2: Analyze the decimal part\\n- Number 9.11 has a decimal part of .11.\\n- Number 9.9 has a decimal part of .9.\\n\\nTo compare the two decimal parts:\\nConvert them into the same number of decimal places:\\n\\n- If we convert 9.9 into 9.90 (adding a zero does not change the value), 9.90 will have the same decimal length as 9.11.\\n- Now, compare 9.11 and 9.90.\\n\\nStep 3: Perform the comparison\\n- We can rewrite 9.11 as 9.110.\\n- We can rewrite 9.90 as 9.900.\\n\\nWhen comparing 9.110 and 9.900:\\n- The integer part (9) is the same.\\n- Compare the first decimal place: 1 vs 9. Clearly, 9 is greater than 1.\\n\\nThus, 9.90 (which is the same as 9.9) is greater than 9.11.\\n\\nFinal Answer: 9.9 is bigger than 9.11.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@task\n",
    "def generate_cot_data(prompt: str) -> List[BaseMessage]:\n",
    "    agent = VanillaAgent.default(ZeroShotCoTPrompt)\n",
    "    _ = agent.run(prompt)\n",
    "    return agent.history\n",
    "\n",
    "\n",
    "flow = ThreadPoolScheduler.map(generate_cot_data, problems) >> format_data\n",
    "flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we just got some data containing steps of thinking, which appearently\n",
    "has better quality compared with our first version.\n",
    "\n",
    "This is not the end, however. Sometimes a single CoT process won't solve the \n",
    "question we gave. To address this, we can use Tree of Thoughts (ToT).\n",
    "\n",
    "## ToT Data Generation\n",
    "\n",
    "ToT data generation will apply the following procedure:\n",
    "\n",
    "1. For each step, the agent will generate multiple answers.\n",
    "2. Another agent will search through the tree by BFS or DFS to check if there\n",
    "   exists a path where the problem has been solved successfully.\n",
    "   \n",
    "ToT will usually improve the success rate of problem solving, and also improve\n",
    "the quality of the data generated. Unfortunately, since ToT applies a new \n",
    "approach of data generation, it won't be as that easy as CoT, which can be \n",
    "simply done by altering the prompt. But no worries! We got your back. \n",
    "\n",
    "We offer a `ToTAgent` in Synthora, which encapsulates all the dirty works for\n",
    "users. In `ToTAgent`, the tree will be searched with DFS, and we only need to \n",
    "make some configurations like `level_size` or `max_turns` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def generate_tot_data(prompt: str) -> List[BaseMessage]:\n",
    "    agent = ToTAgent.default(level_size=2, max_turns=15)\n",
    "    resp = agent.run(prompt)\n",
    "    if resp.is_err:\n",
    "        # the problem is not solved successfully\n",
    "        return []\n",
    "    return agent.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create a even harder question for the agent to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider a regular octagon. How many different triangles can be formed if the octagon is placed inside a circle and we can also use the center of the circle as a vertex for the triangles? Let's think step by step.\n",
      "To solve this problem, let's break it down into manageable steps, considering both the properties of a regular octagon and the addition of the circle's center as a potential vertex for forming triangles.\n",
      "\n",
      "### Step 1: Understand and Define the Components Available for Triangle Formation\n",
      "\n",
      "**Think**: A regular octagon has 8 vertices. Additionally, we have the center of the circle as another point to consider. We need to calculate how many distinct triangles can be formed using any three of these nine points (8 vertices of the octagon + 1 center point of the circle).\n",
      "\n",
      "**Action**: Define our points as follows:\n",
      "- Let \\( V_1, V_2, \\ldots, V_8 \\) be the vertices of the octagon.\n",
      "- Let \\( C \\) be the center of the circle.\n",
      "\n",
      "Now, we need to categorize possible triangles based on whether or not they include the center \\( C \\).\n",
      "\n",
      "### Step 2: Determine the Number of Triangles Formed Using the Octagon Vertices Only\n",
      "\n",
      "**Think**: First, we consider triangles formed using only the vertices of the octagon. Since we are forming a triangle, we need to choose 3 out of the 8 vertices.\n",
      "\n",
      "The number of ways to choose 3 vertices from 8 is given by the combination formula \\( \\binom{n}{k} \\), where \\( n \\) is the total number of items to choose from, and \\( k \\) is the number of items to choose.\n",
      "\n",
      "**Output**: Let's calculate \\( \\binom{8}{3} \\).\n",
      "To find the number of triangles that can be formed using only the vertices of the octagon, we calculate:\n",
      "\n",
      "\\[\n",
      "\\binom{8}{3} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56\n",
      "\\]\n",
      "\n",
      "So, there are 56 triangles that can be formed using only the vertices of the octagon.\n",
      "\n",
      "### Step 3: Determine the Number of Triangles Formed Using the Center of the Circle\n",
      "\n",
      "**Think**: Next, consider triangles that include the center \\( C \\) as one of the vertices. For such triangles, we must choose 2 additional vertices from the 8 vertices of the octagon. This will give us all possible triangles where one of the sides of the triangle radiates from the center \\( C \\).\n",
      "\n",
      "**Action**: Calculate the number of combinations to choose 2 vertices from 8.\n",
      "\n",
      "**Output**: Compute \\( \\binom{8}{2} \\).\n",
      "To find the number of triangles that can be formed using the center of the circle and two of the octagon's vertices, we calculate:\n",
      "\n",
      "\\[\n",
      "\\binom{8}{2} = \\frac{8 \\times 7}{2 \\times 1} = 28\n",
      "\\]\n",
      "\n",
      "So, there are 28 triangles that can be formed using the center of the circle and two vertices of the octagon.\n",
      "\n",
      "### Step 4: Combine the Results\n",
      "\n",
      "**Think**: Now that we have calculated the number of triangles in both scenarios:\n",
      "- 56 triangles using only the vertices of the octagon.\n",
      "- 28 triangles using the center and the vertices of the octagon.\n",
      "\n",
      "We need to add these two results to get the total number of different triangles.\n",
      "\n",
      "**Output**: Calculate the total number of triangles.\n"
     ]
    }
   ],
   "source": [
    "hard_question = (\n",
    "    \"Consider a regular octagon. How many different triangles can be formed \"\n",
    "    \"if the octagon is placed inside a circle and we can also use the center \"\n",
    "    \"of the circle as a vertex for the triangles? Let's think step by step.\"\n",
    ")\n",
    "flow = ThreadPoolScheduler.map(generate_tot_data, problems + [hard_question])\n",
    "results = flow.run()\n",
    "\n",
    "# Get the data for the last question\n",
    "for res in results[-1][1:]:\n",
    "    print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the hard problem has been solved successfully. We can also\n",
    "check the data generated for the question comparing 9.11 and 9.9, just for\n",
    "comparison with previous approaches like CoT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 and 9.9, which one is bigger?\n",
      "To determine which of the two numbers, 9.11 and 9.9, is bigger, we should compare their values. Let's do this step by step.\n",
      "\n",
      "**Think**: We start by comparing each digit of both numbers from left to right. This approach will help us accurately establish which number is greater without direct calculation.\n",
      "\n",
      "1. **First digit**: Both numbers have the digit '9' in the units (integer) place. Since they are equal, we move to the next digit.\n",
      "\n",
      "2. **Second digit**: In the tenths place, both numbers again have '9'. Since these are also equal, we will proceed to check the next digit.\n",
      "\n",
      "3. **Third digit**: For 9.11, the next digit in the hundredths place is '1'. The number 9.9 does not have a digit in this place, which can alternatively be written as 9.90 where the hundredths place is '0'.\n",
      "\n",
      "Therefore, comparing the third digit, '1' (in 9.11) is greater than '0' (in 9.9 or 9.90).\n",
      "\n",
      "**Output**: 9.11 is greater than 9.9 based on the comparison of digits in their decimal places.\n"
     ]
    }
   ],
   "source": [
    "for res in results[1][1:]:\n",
    "    print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example: Scoring Generated Data\n",
    "\n",
    "Now, I believe you already have a brief sense on how to use Synthora to\n",
    "generate simple, CoT and ToT data. At the end of this tutorial, we gonna walk\n",
    "through another case, where we will generate multiple entries of data on the\n",
    "same problem and let one agent to score each of them.\n",
    "\n",
    "First we can define a function used to score two entries of generated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_response(\n",
    "    history1: List[BaseMessage], history2: List[BaseMessage], prompt: str\n",
    ") -> Dict[str, Any]:\n",
    "    response_format = get_pydantic_model('{\"score1\": 0.0, \"score2\": 0.0}')\n",
    "\n",
    "    system_prompt = textwrap.dedent(\n",
    "        f\"\"\"\\\n",
    "        You are a judge to score responses to the following question, scaling from 0 to 10.\n",
    "\n",
    "        {prompt}\n",
    "        \"\"\"  # noqa: E501\n",
    "    )\n",
    "    agent = VanillaAgent.default(system_prompt)\n",
    "    agent.model.config[\"response_format\"] = response_format\n",
    "\n",
    "    # Skip the system message in history\n",
    "    openai_history1 = [msg.to_openai_message() for msg in history1[1:]]\n",
    "    openai_history2 = [msg.to_openai_message() for msg in history2[1:]]\n",
    "\n",
    "    _history1 = \"\\n\".join(\n",
    "        [f\"{msg['role']}: {msg['content']}\" for msg in openai_history1]\n",
    "    )\n",
    "    _history2 = \"\\n\".join(\n",
    "        [f\"{msg['role']}: {msg['content']}\" for msg in openai_history2]\n",
    "    )\n",
    "\n",
    "    agent.history.append(user(f\"Response 1:\\n{_history1}\"))\n",
    "    agent.history.append(user(f\"Response 2:\\n{_history2}\"))\n",
    "    resp = agent.run(\"Please score the two responses.\").unwrap().parsed\n",
    "    result = {\n",
    "        \"chosen\": openai_history1\n",
    "        if resp.score1 > resp.score2\n",
    "        else openai_history2,\n",
    "        \"rejected\": openai_history2\n",
    "        if resp.score1 > resp.score2\n",
    "        else openai_history1,\n",
    "        \"score_chosen\": resp.score1\n",
    "        if resp.score1 > resp.score2\n",
    "        else resp.score2,\n",
    "        \"score_rejected\": resp.score2\n",
    "        if resp.score1 > resp.score2\n",
    "        else resp.score1,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a function of generating two entries of data with the \n",
    "workflow like below, where two tasks (agents) will run concurrently trying to\n",
    "solve the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(system1: str, system2: str, prompt: str) -> Dict[str, Any]:\n",
    "    agent1, agent2 = (\n",
    "        VanillaAgent.default(system1),\n",
    "        VanillaAgent.default(system2),\n",
    "    )\n",
    "    flow = (BaseTask(agent1.run) | BaseTask(agent2.run)).s(prompt)\n",
    "    _ = flow.run()\n",
    "    return score_response(agent1.history, agent2.history, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each problem, we can have a system message for it. For the consideration \n",
    "of convenience, we will use the same simple message for each problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an AI Assistant.\"\n",
    "system1 = [system_message for _ in problems]\n",
    "system2 = [system_message for _ in problems]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can run all the problems concurrently with `ProcessPoolScheduler`, \n",
    "which can run tasks with multi-process approach.\n",
    "\n",
    "> Here we have two nested parallelism, which is supported by nested workflow:\n",
    "> \n",
    "> 1. The outmost workflow works with multi-process, where each problem takes\n",
    ">   up a process to be solved.\n",
    "> 2. Inside each process, there will also be a workflow, where two agents are\n",
    ">   trying to solve the same problem concurrently with multi-thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RemoteError",
     "evalue": "\n---------------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"D:\\Software\\miniconda3\\envs\\syntropix\\Lib\\multiprocessing\\managers.py\", line 253, in serve_client\n    request = recv()\n              ^^^^^^\n  File \"D:\\Software\\miniconda3\\envs\\syntropix\\Lib\\multiprocessing\\connection.py\", line 251, in recv\n    return _ForkingPickler.loads(buf.getbuffer())\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: Can't get attribute 'generate_data' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n---------------------------------------------------------------------------",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m flow \u001b[38;5;241m=\u001b[39m ProcessPoolScheduler\u001b[38;5;241m.\u001b[39mstarmap(\n\u001b[0;32m      2\u001b[0m     BaseTask(generate_data), \u001b[38;5;28mzip\u001b[39m(system1, system2, problems)\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Documents\\synthora\\src\\synthora\\workflows\\scheduler\\process_pool.py:110\u001b[0m, in \u001b[0;36mProcessPoolScheduler.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m     data \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mdict()\n\u001b[0;32m    109\u001b[0m     lock \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 110\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43mMultiProcessContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_context(context)\n\u001b[0;32m    112\u001b[0m cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mget_cursor()\n",
      "File \u001b[1;32mD:\\Documents\\synthora\\src\\synthora\\workflows\\context\\multiprocess_context.py:36\u001b[0m, in \u001b[0;36mMultiProcessContext.__init__\u001b[1;34m(self, data, lock, workflow)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__workflow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m workflow\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__lock\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m lock\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__cursor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36m__setitem__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mD:\\Software\\miniconda3\\envs\\syntropix\\Lib\\multiprocessing\\managers.py:843\u001b[0m, in \u001b[0;36mBaseProxy._callmethod\u001b[1;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[0;32m    841\u001b[0m     dispatch(conn, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecref\u001b[39m\u001b[38;5;124m'\u001b[39m, (token\u001b[38;5;241m.\u001b[39mid,))\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proxy\n\u001b[1;32m--> 843\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m convert_to_error(kind, result)\n",
      "\u001b[1;31mRemoteError\u001b[0m: \n---------------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"D:\\Software\\miniconda3\\envs\\syntropix\\Lib\\multiprocessing\\managers.py\", line 253, in serve_client\n    request = recv()\n              ^^^^^^\n  File \"D:\\Software\\miniconda3\\envs\\syntropix\\Lib\\multiprocessing\\connection.py\", line 251, in recv\n    return _ForkingPickler.loads(buf.getbuffer())\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: Can't get attribute 'generate_data' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n---------------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "flow = ProcessPoolScheduler.starmap(\n",
    "    BaseTask(generate_data), zip(system1, system2, problems)\n",
    ")\n",
    "results = flow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can print the result to see the accepted and rejected data to each\n",
    "problem, according to the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chosen': [{'content': \"How many letters 'r' in the word 'strawberry'?\", 'role': 'user', 'name': 'user'}, {'content': \"The word 'strawberry' contains three letters 'r'.\", 'role': 'assistant', 'name': 'gpt-4o'}], 'rejected': [{'content': \"How many letters 'r' in the word 'strawberry'?\", 'role': 'user', 'name': 'user'}, {'content': 'The word \"strawberry\" contains two letters \\'r\\'.', 'role': 'assistant', 'name': 'gpt-4o'}], 'score_chosen': 10.0, 'score_rejected': 6.0}\n",
      "{'chosen': [{'content': '9.11 and 9.9, which one is bigger?', 'role': 'user', 'name': 'user'}, {'content': '9.11 is larger than 9.9. This is because 9.9 is equivalent to 9.90, and when comparing the numbers 9.11 and 9.90, the first decimal place is the same (9), but the second decimal place shows that 11 is greater than 9.', 'role': 'assistant', 'name': 'gpt-4o'}], 'rejected': [{'content': '9.11 and 9.9, which one is bigger?', 'role': 'user', 'name': 'user'}, {'content': 'The number 9.11 is bigger than 9.9. To compare the two numbers, consider their decimal places: 9.11 has two decimal places and is equivalent to 9.110, while 9.9 is equivalent to 9.90. Since 110 is greater than 90, 9.11 is greater than 9.9.', 'role': 'assistant', 'name': 'gpt-4o'}], 'score_chosen': 10.0, 'score_rejected': 0.0}\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights\n",
    "\n",
    "In this tutorial, we walked through the generation of simple SFT data, CoT\n",
    "data, and ToT data, with the support of workflow in Synthora. At last, we\n",
    "introduced an example, where we can generate multiple entries of data \n",
    "concurrently, taking leverage of the support of nested workflow.\n",
    " \n",
    "\n",
    "## About Synthora\n",
    "\n",
    "Synthora is a lightweight and extensible framework for LLM-driven Agents and \n",
    "ALM research. It provides essential components to build, test and evaluate \n",
    "agents. At its core, Synthora aims to assemble an agent with a single config, \n",
    "thus minimizing your effort in building, tuning, and sharing agents.\n",
    "\n",
    "If you find this tutorial interesting, feel free to visit our\n",
    "[GitHub Repo](https://github.com/syntropix-ai/synthora) and leave a starðŸŒŸ!\n",
    "Any feedback from you will mean a lot to us."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
