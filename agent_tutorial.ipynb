{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji7StnRm8H1z"
      },
      "source": [
        "# Welcome to the Agent Exploration Colab! ðŸŽ¯ðŸ¤–\n",
        "\n",
        "This Colab notebook is designed to introduce the fundamental components of an agent, including **prompts, tools, and callbacks**. We will explore how agents interact and how multiple agents can work together efficiently.\n",
        "\n",
        "\n",
        "By the end of this notebook, you will have a clear understanding of:\n",
        "\n",
        "âœ… The essential building blocks of an agent\n",
        "\n",
        "âœ… How to enhance agent capabilities using tools and callbacks\n",
        "\n",
        "âœ… The fundamentals of multi-agent collaboration\n",
        "\n",
        "\n",
        "\n",
        "Letâ€™s dive in and start building intelligent agents! ðŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXCDNX-k9s3A"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You are probably excited to start already, but before that, there are some\n",
        "prerequisites you need to prepare. (Sorry!)\n",
        "\n",
        "### Install Synthora and other packages\n",
        "\n",
        "Synthora requires Python 3.10+. You can install Synthora via pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpJiuK7p9yfq"
      },
      "outputs": [],
      "source": [
        "%pip install synthora==\"0.1.10\"\n",
        "%pip install wikipedia\n",
        "%pip install googlesearch-python\n",
        "%pip install trafilatura\n",
        "%pip install bs4\n",
        "%pip install \"rich[jupyter]\"\n",
        "%pip install python-pptx\n",
        "%pip install requests\n",
        "%pip install duckduckgo_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n5E1XcdP-e6b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "from synthora.agents import VanillaAgent, ReactAgent\n",
        "from synthora.prompts import BasePrompt\n",
        "from synthora.prompts.buildin import ZeroShotCoTPrompt, ZeroShotReactPrompt\n",
        "from synthora.callbacks.output_handler import OutputHandler\n",
        "from synthora.callbacks import RichOutputHandler\n",
        "from synthora.toolkits.file_toolkit import FileToolkit\n",
        "from synthora.toolkits.search_toolkit import SearchToolkit\n",
        "from synthora.toolkits.webpage_toolkit import TrafilaturaWebpageReader\n",
        "from synthora.toolkits.slides import SlidesToolkit\n",
        "from synthora.toolkits.decorators import tool\n",
        "from synthora.models import OpenAIChatBackend\n",
        "from synthora.messages import user\n",
        "from typing import Dict, List\n",
        "\n",
        "from synthora.workflows import task\n",
        "from synthora.workflows.scheduler.thread_pool import ThreadPoolScheduler\n",
        "from synthora.toolkits.search_toolkits import search_wikipedia\n",
        "from pydantic import BaseModel\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3XIu-_WU8pc"
      },
      "source": [
        "## The Difference Between LLMs and Agents ðŸ¤–"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqxhIkFIVY1R"
      },
      "source": [
        "### Setup your API Key\n",
        "\n",
        "In this tutorial, we will use OpenAI as our model provider."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvXDr-4d_wlZ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key here: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viVuWRjnVpID"
      },
      "source": [
        "Next, let's define an OpenAI Model and have a try!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "7MAVdIgqO4ZW"
      },
      "outputs": [],
      "source": [
        "model = OpenAIChatBackend(api_key=os.environ[\"OPENAI_API_KEY\"], model_type=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOt32Y2UWknk"
      },
      "source": [
        "You can use function `user` to define a message from user!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6OEQni-POqW",
        "outputId": "f69c0ae3-49a0-4ad8-ef4c-43fa7424930a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'content': 'hello, my name is Tom.', 'role': 'user', 'name': 'user'}"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message = user(\"hello, my name is Tom.\")\n",
        "message.to_openai_message()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC1QsHKnWztF"
      },
      "source": [
        "Imagine you're at a party. An LLM is like someone with amazing knowledge but terrible memory - they'll forget your name right after you tell them! \n",
        "\n",
        "Let me show you what I mean:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GZXdjW8YPCo-",
        "outputId": "10d981d6-7d23-4b20-81ab-932fc8e3c71f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello Tom! How can I assist you today?'"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(model.run([message]).content)\n",
        "# Hello Tom! How can I assist you today?\n",
        "\n",
        "print(model.run([user(\"What is my name?\")]).content)\n",
        "# I'm sorry, but I don't have access to personal data about individuals unless it's shared with me during our conversation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's because llm model is stateless, it will not save our previous conversation.\n",
        "\n",
        "If we want model to have previous context, we need to provide them manully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.run([message, user(\"What is my name?\")]).content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4lnj3JCW95J"
      },
      "source": [
        "But an Agent? They're like a person with both knowledge AND memory! \n",
        "\n",
        "They'll remember your name throughout the conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWY2ID2fB9jc"
      },
      "outputs": [],
      "source": [
        "agent = VanillaAgent.default()\n",
        "agent.run(\"Hello, my name is Tom, how are you today?\")\n",
        "resp = agent.run(\"What is my name?\")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unlike the stateless LLM model, agents maintain state and can remember information from previous interactions. As we can see, when we ask the agent 'What is my name?' after introducing ourselves, it correctly remembers that our name is Tom. This is because agents maintain conversation history and context between interactions, allowing them to reference and use previously shared information.\n",
        "\n",
        "This stateful nature makes agents more suitable for ongoing conversations and tasks that require memory of past interactions. The agent doesn't need to be explicitly provided with the conversation history each time - it automatically maintains this context internally.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Prompts: The Core of Agent Behavior ðŸŽ¯\n",
        "\n",
        "Prompts are the foundation of how agents think and behave. They act as instructions or guidelines that shape how an agent interprets and responds to input. Let's explore how prompts work and how we can customize them to create agents with specific behaviors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at a simple example to understand how different prompts affect agent behavior. \n",
        "\n",
        "We'll ask agents to count the number of 'p's in the word 'applepiepp'.\n",
        "\n",
        "First, with a default agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqUjIs-6CaXa"
      },
      "outputs": [],
      "source": [
        "resp = agent.run(\"How many 'p's are in the word applepiepp\")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The agent might give an incorrect answer because it's making a quick judgment without breaking down the problem.\n",
        "\n",
        "Now, let's use an agent with Chain-of-Thought prompting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZZ_m9I9C1NS"
      },
      "outputs": [],
      "source": [
        "agent = VanillaAgent.default(ZeroShotCoTPrompt)\n",
        "resp = agent.run(\"How many 'p's are in the word applepiepp\")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "With Chain-of-Thought prompting, we see a significant improvement in accuracy because the agent:\n",
        "\n",
        "1. Systematically breaks down the word: 'a-p-p-l-e-p-i-e-p-p'\n",
        "2. Identifies and counts each 'p': p1, p2, p3, p4, p5\n",
        "3. Arrives at the correct answer: 5 p's\n",
        "\n",
        "This demonstrates how prompting strategies can significantly impact an agent's accuracy. By encouraging step-by-step reasoning through Chain-of-Thought prompting, we reduce errors and get more reliable results. The ZeroShotCoTPrompt helps the agent think more carefully and show its work, leading to better problem-solving.\"\n",
        "\n",
        "\n",
        "### Key Takeaways About Prompts ðŸ”‘\n",
        "\n",
        "From this simple counting example, we can draw several important conclusions about prompts:\n",
        "\n",
        "1. **Impact on Accuracy**: The right prompt can significantly improve an agent's accuracy. While the default agent made counting errors, the Chain-of-Thought prompt led to correct results.\n",
        "\n",
        "2. **Reasoning Process**: Prompts don't just affect the final answer - they shape how an agent approaches problem-solving. \n",
        "\n",
        "3. **Task Suitability**: Even for seemingly simple tasks like counting letters, the choice of prompt can make a significant difference in performance. This suggests that for more complex tasks, careful prompt design becomes even more crucial.\n",
        "\n",
        "Understanding these aspects of prompts is essential for developing effective AI applications, as the right prompt can be the difference between success and failure in agent-based tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkBTn7ErHewK"
      },
      "source": [
        "\n",
        "The `Prompt` functionality in `synthora` provides a way to create and manage customizable prompt templates with dynamic argument formatting.\n",
        "\n",
        "This system integrates with agents like `VanillaAgent` and allows for flexible prompt handling during runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrYI_f4ODIIQ"
      },
      "outputs": [],
      "source": [
        "prompt = \"You are an AI Assistan. Your name is {name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzG2y1R5DSYM"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    agent = VanillaAgent.default(prompt=prompt)\n",
        "    resp = agent.run(\"What is your name?\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Oops, it seems the agent is not able to use the prompt.\n",
        "\n",
        "That's because in our prompt, we have a placeholder `{name}`, which should be replaced with the actual name.\n",
        "\n",
        "To fix this, we can provide the `name` argument to the agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0EzXjiQD1UG"
      },
      "outputs": [],
      "source": [
        "resp = agent.run(\"What is your name?\", name=\"Tom\")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jTp7Oh9HYEu"
      },
      "source": [
        "## Callback: A Powerful Tool for Monitoring and Logging an Agent ðŸ”\n",
        "\n",
        "Unlike LLM Model, agent provides a higher level of abstraction, which makes it more difficult to understand what's happening inside the agent.\n",
        "\n",
        "To monitor and log the agent's behavior, we can use callbacks, which provide a powerful way to log and track events throughout your agent's workflow.\n",
        "\n",
        "---\n",
        "\n",
        "### What Are Callbacks?\n",
        "\n",
        "Callbacks act as event listeners, providing updates on various stages of your agent's operations. They notify you when:\n",
        "\n",
        "- The agent starts processing.\n",
        "- A tool is utilized.\n",
        "- Decisions are made.\n",
        "- An error occurs.\n",
        "- ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To add a callback to an agent, we can simply pass a list of callbacks to the agent's constructor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw6JRwyuD8mY"
      },
      "outputs": [],
      "source": [
        "agent = ReactAgent.default(prompt=ZeroShotReactPrompt, handlers=[RichOutputHandler()])\n",
        "resp = agent.run(\"How many 'p's are in the word applepiepp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we use `RichOutputHandler` as a callback, which will print the agent's response in a rich format.\n",
        "\n",
        "If you provide a list of callbacks, the agent will execute them in the order you provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tools: Adding External Capabilities to Agents ðŸ› ï¸\n",
        "\n",
        "Most of the time, agent is a powerful tool that can be used to solve various problems. \n",
        "\n",
        "However, sometimes, they are not enough, so we need to add some external tools to improve the agent's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But, how can an agent use tools? How can the agent know how to use the tool?\n",
        "\n",
        "This happens at the model level.\n",
        "\n",
        "To let the model know how to use the tool, we need to provide the tool's description and signature to the model.\n",
        "Including the tool's name, description, and parameters.\n",
        "\n",
        "This can be very complex, that's why we provide a `tool` decorator to help you get the tool's description and signature.\n",
        "\n",
        "> What is `decorator` in python?\n",
        "\n",
        "> Decorator is a function that modifies the behavior of another function.\n",
        "\n",
        "> It is often used to wrap the original function with some additional functionality.\n",
        "\n",
        "> For example, you can use it to log the function's input and output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STjkhOX4FeVM"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    return a * b\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers\"\"\"\n",
        "    return a + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After you decorate the function with `@tool`, you can get the tool's description and signature by calling `tool.schema`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGlDMJtRI8rz"
      },
      "outputs": [],
      "source": [
        "print(json.dumps(multiply.schema, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Synthora` will automatically add the tool's description and signature to the model when you pass the tool to the agent.\n",
        "\n",
        "Now, let's see how to use the tool in an agent and how the tools can improve the agent's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu4haW4YJWaq"
      },
      "outputs": [],
      "source": [
        "agent = VanillaAgent.default()\n",
        "resp = agent.run(\"8743687 * 23478 = ?\")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "205284283386"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "8743687 * 23478"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Oops, it's very close, but not exactly correct.\n",
        "\n",
        "Now, let's add the tool to the agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea4RFz_qJ20U"
      },
      "outputs": [],
      "source": [
        "agent = VanillaAgent.default(tools=[multiply], handlers=[OutputHandler()])\n",
        "resp = agent.run(\"8743687 * 23478 = ?\")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the agent can now use the tool to solve the problem and get the correct answer!\n",
        "\n",
        "Now, let's add another tool to the agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51h8mgBjKYpL"
      },
      "outputs": [],
      "source": [
        "agent = VanillaAgent.default(tools=[multiply, add], handlers=[OutputHandler()])\n",
        "resp = agent.run(\"8743687 * 23478 + 983479 = ?\")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR8XG9XhKnKz"
      },
      "outputs": [],
      "source": [
        "8743687 * 23478 + 983479"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can move on to more complex tasks, a real world example.\n",
        "\n",
        "We will provide a set of tools to the agent, and let the agent can search the web, read the webpage, and generate a slides for us.\n",
        "\n",
        "It's not hard! Synthora has already provided a set of tools for you, you just need to add them to your agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z1AKR78KpLN"
      },
      "outputs": [],
      "source": [
        "agent = VanillaAgent.default(\n",
        "    tools=SlidesToolkit(api_key=getpass(\"Your UNSPLASH_API_KEY\")).sync_tools + [*TrafilaturaWebpageReader(full_text=True).sync_tools],\n",
        "    handlers=[OutputHandler()],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1ctkJ_qLS6D"
      },
      "outputs": [],
      "source": [
        "resp = agent.run(\"generate a PPT about https://ai4ocean.xyz, including Products, Team, Research, Projects, Publications, Education, Partnership, etc. \")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If everything goes well, you can see the agent uses multiple tools multiple times to solve the problem.\n",
        "\n",
        "And you will get a PPT about the given topic under `cache` folder.\n",
        "\n",
        "Is it cool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Agent Collaboration: When One is Not Enough ðŸ¤\n",
        "\n",
        "In many cases, a single agent may not be sufficient to solve a complex problem. This is where multi-agent collaboration comes in.\n",
        "\n",
        "By combining the strengths of multiple agents, you can tackle more challenging tasks and achieve better results.\n",
        "\n",
        "Now, let's see how to use multi-agent collaboration to solve a problem.\n",
        "\n",
        "We will use two agents to solve a problem:\n",
        "\n",
        "1. A web search agent to search the web for the best resources.\n",
        "2. A file operation agent to write the resources to a file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGK7EokfLYe9"
      },
      "outputs": [],
      "source": [
        "search_agent = VanillaAgent.default(\n",
        "    \"\"\"You are a web search agent. You are tasked with\n",
        "    finding the best resources on the web for a given topic.\n",
        "    You should provide a list of the top 5 resources that you find,\n",
        "    along with a brief summary of each resource.\n",
        "    You should also provide a brief summary of the topic itself. \"\"\",\n",
        "    name=\"WebSearchAgent\",\n",
        "    tools=[SearchToolkit().search_duckduckgo],\n",
        ")\n",
        "search_agent.description = \"\"\"\n",
        "A web search agent that finds the best resources on the web for a given topic.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5j2E80sMJBy"
      },
      "outputs": [],
      "source": [
        "file_operate_agent = VanillaAgent.default(\n",
        "    \"\"\"You are an AI assistant that helps users with file operations.\"\"\",\n",
        "    name=\"FileOperationAssistant\",\n",
        "    tools=[FileToolkit().write_file],\n",
        ")\n",
        "file_operate_agent.description = \"\"\"\n",
        "An AI assistant that helps users with file operations.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To simplify the multi-agent collaboration, the agent in Synthora can be seen as a `tool` that can be used in other agents.\n",
        "\n",
        "So, we can simply pass the `search_agent` and `file_operate_agent` to the `supervisor` agent.\n",
        "\n",
        "The `supervisor` agent will use the `search_agent` to search the web for the best resources, and use the `file_operate_agent` to write the resources to a file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqL-g5NmMJwM"
      },
      "outputs": [],
      "source": [
        "supervisor = VanillaAgent.default(\n",
        "    tools=[search_agent, file_operate_agent],\n",
        "    handlers=[OutputHandler()],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfeP9Nq2MLqR"
      },
      "outputs": [],
      "source": [
        "resp = supervisor.run(\n",
        "    \"Find some llm tutorials for me and write them to a file named llm.md.\",\n",
        ")\n",
        "print(resp.unwrap().content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If everything goes well, you can see the `supervisor` agent calls the `search_agent` to search the web and the `file_operate_agent` to write the resources to a file.\n",
        "\n",
        "And you will get a file named `llm.md` under the current working directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4LjzLmRS61"
      },
      "source": [
        "## Workflow: Orchestrating Agents with Flexibility\n",
        "\n",
        "Workflow is a powerful system in Synthora that can be used to orchestrate agents to solve various problems, allowing users to define their own workflows with a high level of flexibility.\n",
        "\n",
        "In this tutorial, we will explore how to use workflow to manage and automate tasks efficiently. We will start with basic concepts and gradually move to more advanced features. Thanks to the flexibility of workflow, the overall process is simple and can be easily customized.\n",
        "\n",
        "Now, if you are ready, let's start!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "su1wtVemMRXQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from synthora.workflows import task\n",
        "from synthora.workflows.base_task import BaseTask\n",
        "from synthora.workflows.scheduler import ThreadPoolScheduler\n",
        "from synthora.workflows.scheduler.base import BaseScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MISN5eeLRcd7"
      },
      "source": [
        "### Components of Workflow\n",
        "\n",
        "A workflow in Synthora is composed of three main components: scheduler, task, and context.\n",
        "\n",
        "- **Task**: The basic execution unit, usually a function.\n",
        "- **Scheduler**: Invokes tasks either in parallel or in series according to specific strategies.\n",
        "- **Context**: Allows tasks to read and store information during execution, and supports advanced features like loops and conditional statements.(Will not mention today)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar like `tool`, you can also use a decorator to declare a task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2Go8vd_FRZqU"
      },
      "outputs": [],
      "source": [
        "@task\n",
        "def add_task(x: int, y: int) -> int:\n",
        "    return x + y\n",
        "\n",
        "def add(x: int, y: int) -> int:\n",
        "    return x + y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can call the task directly just like a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1OeuZr_Rz2u",
        "outputId": "3bc3f7f4-af2c-46a3-81d5-3564625a740e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "add_task(1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYStUVpbR36r"
      },
      "source": [
        "### Task Signature\n",
        "\n",
        "Task signatures allow you to predefine task parameters, enabling users to implement more complex functionalities.\n",
        "\n",
        "By using task signatures, you can set default values for the parameters of a task, making it easier to reuse tasks with predefined configurations. \n",
        "\n",
        "This is particularly useful when you need to run the same task multiple times with the same parameters or when you want to create more complex workflows by chaining tasks together.\n",
        "\n",
        "> In one word, signature is a way to predefine the parameters of a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22rTiWckR1VY",
        "outputId": "e0f952fd-d6f1-4121-8378-fa4cd01eea96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "f6253f4f-8bbf-47cf-8ce5-66b92e4b49e0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "add_task.s(1)\n",
        "# or\n",
        "# add_task.signature(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78EEXQ-hSOz6",
        "outputId": "80d088e0-d97d-40ef-b9c2-94fdf5403569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "add_task() takes 2 positional arguments but 3 were given\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    add_task(1, 2)  # will raise an error\n",
        "except TypeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the task has a signature, which means the task has a default parameter.\n",
        "\n",
        "This means you only need to provide **ONE** parameter to the task!."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsF-2jtZSQSw",
        "outputId": "7b9e4cb4-98f6-4030-a22c-0cf5fc44be89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "add_task(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlWLzZSZSXuc"
      },
      "source": [
        "### Serial and Parallel\n",
        "\n",
        "In Synthora, tasks can be executed either serially or in parallel, providing flexibility in how workflows are structured.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0XFc6fRSfIj"
      },
      "source": [
        "### Serial Tasks\n",
        "\n",
        "Serial tasks are executed one after another, with each task's output being passed as input to the next task. This allows for a linear flow of data through the tasks.\n",
        "\n",
        "You can use Python operators to declare serial workflows, which can simplify the creation process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjfQGXc1STFL",
        "outputId": "8df61288-afaf-4baf-a91f-a22f327c3070"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flow = BaseTask(add) >> BaseTask(add).s(1) >> BaseTask(add).s(2)\n",
        "flow.run(1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52PER6hdS3KN"
      },
      "source": [
        "why the output is 5?\n",
        "\n",
        "> This is because the workflow will add the return value of the previous task as a parameter to the next task.\n",
        "\n",
        ">First Step: The flow gets the input: (1, 1), and passes it to the first task. The first task returns 1 + 1 = 2.\n",
        "\n",
        ">For the second task, we have pre-specified the input as 1, which, combined with the return value of the previous task (2), is passed as parameters. The second task returns 2 + 1 = 3.\n",
        "\n",
        "> Similarly, the third task returns 3 + 2 = 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e26B5Se2TBwP"
      },
      "source": [
        "### Parallel Tasks\n",
        "Parallel tasks are executed simultaneously, with each task receiving the same input parameters. This allows for concurrent processing and can significantly speed up the workflow when tasks are independent of each other.\n",
        "\n",
        "Parallel tasks can also be declared using expressions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh4fzBGZTC-A",
        "outputId": "6a18c3bc-ab04-4d44-9d7a-f994b2f6e32b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 3, 4]"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flow = (\n",
        "    BaseTask(add).s(0)\n",
        "    | BaseTask(add).s(1)\n",
        "    | BaseTask(add).s(2)\n",
        "    | BaseTask(add).s(3)\n",
        ")\n",
        "flow.run(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akk08PfXTTgJ"
      },
      "source": [
        "Unlike serial tasks, the input parameters for parallel tasks are passed to each task individually. For example:\n",
        "\n",
        "task1 receives parameters 0, 1\n",
        "\n",
        "task2 receives parameters 1, 1\n",
        "\n",
        "task3 receives parameters 2, 1\n",
        "\n",
        "task4 receives parameters 3, 1\n",
        "\n",
        "Each task will process its own set of parameters independently and simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's move on to a more complex example.\n",
        "\n",
        "In marine science, it is not enough just using a general LLM model to answer the question.\n",
        "\n",
        "We need to use a marine expert to answer the question!\n",
        "\n",
        "By using `Fine-Tuning`, we can inject the marine knowledge into the model.\n",
        "\n",
        "But how can we get the data to train the model?\n",
        "\n",
        "We can use a `workflow` to generate them!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need to define the data structure we want to generate.\n",
        "\n",
        "`MarineDataItem` is the data structure we want to generate.\n",
        "\n",
        "It contains a question and an answer.\n",
        "\n",
        "`MarineData` is a list of `MarineDataItem`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "3pHtEomnTSxd"
      },
      "outputs": [],
      "source": [
        "class MarineDataItem(BaseModel):\n",
        "    question: str\n",
        "    answer: str\n",
        "\n",
        "class MarineData(BaseModel):\n",
        "    items: List[MarineDataItem]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we need to define the task we want to use.\n",
        "\n",
        "`search_wikipedia_task` is a task that searches the web for the marine knowledge.\n",
        "\n",
        "`generate_data` is a task that generates the data by using these marine knowledge.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "aMJyxbIoTch8"
      },
      "outputs": [],
      "source": [
        "@task\n",
        "def search_wikipedia_task(concepts: str) -> str:\n",
        "    try:\n",
        "        return search_wikipedia.run(concepts).unwrap()\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "Ng5p1oEtTrzB"
      },
      "outputs": [],
      "source": [
        "@task\n",
        "def generate_data(doc: str) -> MarineData:\n",
        "    agent = VanillaAgent.default(\"You are a marine data expert. You are given a document and you need to generate several questions and answers about the document.\")\n",
        "    agent.model.config[\"response_format\"] = MarineData\n",
        "    results = agent.run(doc).unwrap().parsed\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we need to define the concepts we want to search and generate the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "34O6b1BtTyWI"
      },
      "outputs": [],
      "source": [
        "concepts = [\n",
        "    \"Acoustic seabed classification\",\n",
        "    \"Advection\",\n",
        "    # \"Ageostrophy\",\n",
        "    # \"Baroclinity\",\n",
        "    # \"Coriolis frequency\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can define the workflow.\n",
        "\n",
        "The first step is to search the web for the marine knowledge.\n",
        "\n",
        "The second step is to generate the data by using these marine knowledge.\n",
        "\n",
        "\n",
        "To improve the efficiency, we can use `ThreadPoolScheduler` to run the tasks in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "xo66iGGnT_J1"
      },
      "outputs": [],
      "source": [
        "flow = ThreadPoolScheduler.map(search_wikipedia_task >> generate_data, concepts)\n",
        "datas = flow.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDSe10YgUCIQ",
        "outputId": "4b8dcca9-4097-4b3f-92cd-a1ffae10e8cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is acoustic seabed classification?\n",
            "Acoustic seabed classification is the partitioning of a seabed acoustic image into discrete physical entities or classes. It is used to characterize the seabed and its habitats by linking the classified regions to their physical, geological, chemical, or biological properties.\n",
            "------------------------------\n",
            "What are the two main categories of seabed classification based on acoustic properties?\n",
            "The two main categories of seabed classification based on acoustic properties are surficial seabed classification and sub-surface seabed classification.\n",
            "------------------------------\n",
            "What is the focus of surficial seabed classification?\n",
            "Surficial seabed classification is primarily concerned with distinguishing the marine benthic habitat characteristics such as hard, soft, rough, smooth, mud, sand, clay, and cobble of the surveyed area.\n",
            "------------------------------\n",
            "Which technologies are commonly used for surficial seabed classification?\n",
            "The most commonly used technologies for surficial seabed classification are multibeam echosounders, sidescan sonar systems, and acoustic ground discrimination systems (AGDS).\n",
            "------------------------------\n",
            "How does sub-surface imaging differ from surficial imaging in acoustic seabed classification?\n",
            "Sub-surface imaging uses lower frequency sound to achieve higher penetration, whereas surficial imaging employs higher frequencies to provide higher resolution imagery, especially in shallow water.\n",
            "------------------------------\n",
            "What are some of the technologies used for acoustic seabed classification?\n",
            "Technologies used for acoustic seabed classification include multibeam echosounders, sidescan sonar, single-beam echosounders, interferometric systems, and sub-bottom profilers.\n",
            "------------------------------\n",
            "What is advection in the context of physics and earth sciences?\n",
            "Advection is the transport of a substance or quantity by the bulk motion of a fluid, carrying the properties of the substance with it.\n",
            "------------------------------\n",
            "What types of substances or quantities can be advected?\n",
            "Any substance or conserved extensive quantity, such as pollutants, silt, energy, or enthalpy, can be advected by a fluid that can contain it.\n",
            "------------------------------\n",
            "How is the motion of the fluid described mathematically during advection?\n",
            "The fluid's motion is described mathematically as a vector field.\n",
            "------------------------------\n",
            "What is an example of advection given in the document?\n",
            "An example of advection is the transport of pollutants or silt in a river by the bulk water flow downstream.\n",
            "------------------------------\n",
            "What does the scalar field represent in the context of advection?\n",
            "In advection, the scalar field represents the distribution of the transported material over space.\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "for data in datas:\n",
        "  for item in data.items:\n",
        "    print(item.question)\n",
        "    print(item.answer)\n",
        "    print('-' * 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqbRRZ9_UE_l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
